
基础知识：
    python(2.x)
    scrapy
    xpath

在线文档：
    https://docs.python.org/2/library/
    https://scrapy-chs.readthedocs.io/zh_CN/1.0/
    http://www.w3school.com.cn/xpath/

项目结构：                               说明：

yellowpage                              根目录
    conf                                配置文件目录
        categories.csv                  类别配置文件，大类、小类以\t分割，小类以逗号分割
        cities.csv                      城市配置文件，州缩写、州名称、城市名称以\t,城市以逗号分割
    logs                                日志目录
        yellowpage.log                  爬虫日志文件，爬虫执行报错，如被禁，错误信息记录在该文件
    yellowpage                          爬虫执行文件
        spiders                         爬虫目录
            __init__.py                 初始化文件，读取类别、城市信息放入MyGlobals变量，以被yellowpagespider.py中使用
            yellowpagespider.py         爬虫程序，构造爬虫爬取url，解析html结构，获取要抓取的信息放入到items中
        __init__.py
        constants.py                    MyGlobals变量定义文件，再yellowpagespider.py中import引入
        fetch_free_proxyes.py           ip代理抓取程序，抓取后多线程测试代理是否可用，可用则加入字典，
                                        在middlewares.py中引入，固定时间（2小时）更新可用的代理。
        items.py                        item类定义
        middlewares.py                  中间件定义，包括UserAgentMiddleware,MyHttpProxyMiddleware中间件，定义爬虫发起http请求时的操作
        pipelines.py                    持久化操作，spider抓取的items信息，如何输出，比如到文件，到sdtout等
        settings.py                     爬虫配置文件，包括中间件配置，爬虫请求频率，自定义配置等
    spider_start.sh                     爬虫启动脚本


说明：
    1、由于python CLI,scrapy本身并不支持多线程爬取。如为了提高爬取速度，可将categories.csv，cities.csv拆分到多个项目中，启多个爬虫多进程爬取
    2、针对yellowpage.com,yelp.com网站爬取，ip代理是必须的。入未使用定时更新代理，一段时间以后网站会针对ip进行限制，日志文件中可观察到错误信息